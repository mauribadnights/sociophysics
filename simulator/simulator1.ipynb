{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d905379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from libraries.dataManipulation import *\n",
    "from libraries.gridManipulation import *\n",
    "from csv import DictReader\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import time\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d64c99cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sociophysicsDataHandler import SociophysicsDataHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66976844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_unix_timestamp(datetime_utc):\n",
    "    return datetime_utc.timestamp()\n",
    "    return (datetime_utc - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f61990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for train\n",
    "def check_train(t):\n",
    "    df_train_present = train_data[(train_data['departure_unix'] > t) & (train_data['arrival_unix'] < t)]\n",
    "    \n",
    "    if (df_train_present.empty):\n",
    "        train_present_top = False\n",
    "        train_present_bottom = False\n",
    "        return\n",
    "    \n",
    "    loc = df_train_present.loc[0]\n",
    "    \n",
    "    if (loc == 'top'):\n",
    "        train_present_top = True\n",
    "        train_present_bottom = False\n",
    "    else:\n",
    "        train_present_top = False\n",
    "        train_present_bottom = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f13f4a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data():\n",
    "    train_data = SociophysicsDataHandler()\n",
    "    train_data.fetch_prorail_train_information(station='ehv')\n",
    "    train_data = train_data.train_information\n",
    "    \n",
    "    train_data['arrival_unix'] = train_data['arrival_time'].apply(to_unix_timestamp)\n",
    "    train_data['departure_unix'] = train_data['departure_time'].apply(to_unix_timestamp)\n",
    "    \n",
    "    train_data_no_nan = train_data.dropna()\n",
    "    #limit rows to 1 row per train (individual door information deleted)\n",
    "    train_data_filtered = train_data_no_nan.drop_duplicates('arrival_time')\n",
    "    \n",
    "    unix_timestamp_day_start =  min(people_in_dictionary_on.keys())\n",
    "    unix_timestamp_day_end =  max(people_in_dictionary_on.keys())\n",
    "    \n",
    "    day_train_data = train_data_filtered[(train_data_filtered['arrival_unix'] > unix_timestamp_day_start) & (train_data_filtered['departure_unix'] < unix_timestamp_day_end)]\n",
    "    day_train_data = day_train_data.reset_index(drop=True)\n",
    "    \n",
    "    day_train_data = day_train_data.assign(train_position=lambda x: np.where(x['door_y'] > 2500, 'top', 'bottom'))\n",
    "    day_train_data = day_train_data.drop(columns=['arrival_time', 'departure_time','door_no', 'door_x', 'door_y','station'])\n",
    "    \n",
    "    return day_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd0bf7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spawn people\n",
    "def spawn_people(timestamp):\n",
    "    global current_ID, simulation_tuple\n",
    "    if timestamp in people_in_dictionary_off:\n",
    "        spawn_zones = people_in_dictionary_off[timestamp]\n",
    "        for zone in spawn_zones:\n",
    "            zone = int(zone)\n",
    "            offboarding_people_locs[current_ID] = zone\n",
    "            simulation_tuple.extend([[current_ID,True,False,timestamp,zone]])\n",
    "            \n",
    "            density[zone_to_coordinate(zone)] += 1/zone_area\n",
    "            current_ID += 1\n",
    "    \n",
    "    if timestamp in people_in_dictionary_on:\n",
    "        spawn_zones = people_in_dictionary_on[timestamp]\n",
    "        for zone in spawn_zones:\n",
    "            zone = int(zone)\n",
    "            onboarding_people_locs[current_ID] = zone\n",
    "            simulation_tuple.extend([[current_ID,False,True,timestamp,zone]])\n",
    "            \n",
    "            density[zone_to_coordinate(zone)] += 1/zone_area\n",
    "            current_ID += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddac2ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put an obstacle in a zone by making the probability of going to that zone 0\n",
    "def block_zone(markov_matrix, zone):\n",
    "    m = markov_matrix.copy()\n",
    "    m[zone] = 0\n",
    "    return m\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffedc5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a library of people spawning\n",
    "def get_spawn_lib(onboarding_offboarding):\n",
    "    \n",
    "    if onboarding_offboarding == 'onboarding':\n",
    "        df = pd.read_csv('../people_input/incoming_people_entering_5_0.csv', sep = ';', header = None)\n",
    "        df = df.set_index(0)\n",
    "        spawn_dict = df.to_dict()[1]\n",
    "        for key in spawn_dict.keys():\n",
    "            spawn_dict[key] = ast.literal_eval(spawn_dict[key])\n",
    "            \n",
    "    elif onboarding_offboarding == 'offboarding':\n",
    "        df = pd.read_csv('../people_input/incoming_people_offboarding_5_0.csv', sep = ';', header = None)\n",
    "        df = df.set_index(0)\n",
    "        spawn_dict = df.to_dict()[1]\n",
    "        for key in spawn_dict.keys():\n",
    "            spawn_dict[key] = ast.literal_eval(spawn_dict[key])\n",
    "        \n",
    "    else:\n",
    "        print(\"Error: \" + onboarding_offboarding + \" is not a valid input\")\n",
    "        return None\n",
    "    \n",
    "    return spawn_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48f4dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine the density based on the locations of people\n",
    "#DEPRECATED\n",
    "def calculate_density():\n",
    "    locs = {**onboarding_people_locs,**offboarding_people_locs}\n",
    "    \n",
    "    density = density_0\n",
    "    \n",
    "    #Cycle through all the people in the locs dictionary\n",
    "    for i in locs.keys():\n",
    "        density[zone_to_coordinate(locs[i])] += 1/zone_area\n",
    "        \n",
    "    return density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05e148fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the density matrix into a 3x3 matrix of surrounding zone densities\n",
    "#The area of 5x5 squares around the midpoint will be taken into account by averaging them into the 3x3 matrix\n",
    "#The midpoint will be a tuple of the form (zone_row,zone_column)\n",
    "def get_density_matrix(density_matrix, current_zone):\n",
    "    density_matrix_5 = np.zeros([5,5])\n",
    "    midpoint = zone_to_coordinate(current_zone)\n",
    "\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            coords = ( min(max(midpoint[0]+i-2,0),zone_rows-1), min(max(midpoint[1]+j-2,0),zone_columns-1) )\n",
    "            density_matrix_5[i,j] = density[coords]\n",
    "    \n",
    "    #Convert the 5x5 density matrix into a 3x3 one\n",
    "    density_matrix_5_3 = np.zeros([5,3])\n",
    "    \n",
    "    density_matrix_5_3[:,0] = 0.3 * density_matrix_5[:,0] + 0.7 * density_matrix_5[:,1]\n",
    "    density_matrix_5_3[:,1] = density_matrix_5[:,2]\n",
    "    density_matrix_5_3[:,2] = 0.7 * density_matrix_5[:,3] + 0.3 * density_matrix_5[:,4]\n",
    "    \n",
    "    density_matrix_3 = np.zeros([3,3])\n",
    "    \n",
    "    density_matrix_3[0,:] = 0.3 * density_matrix_5_3[0,:] + 0.7 * density_matrix_5_3[1,:]\n",
    "    density_matrix_3[1,:] = density_matrix_5_3[2,:]\n",
    "    density_matrix_3[2,:] = 0.7 * density_matrix_5_3[3,:] + 0.3 * density_matrix_5_3[4,:]\n",
    "    \n",
    "    #People shouldn't be repelled from their own zones, so make the middle denisty zero\n",
    "    density_matrix_3[1,1] = 0\n",
    "    \n",
    "    density_matrix_3 = density_matrix_3.flatten() #Put the matrix in the flattened form\n",
    "    \n",
    "    #Add zeros for void_zones density\n",
    "    for i in range(void_zones):\n",
    "        density_matrix_3 = np.append(density_matrix_3,0)\n",
    "    \n",
    "    return density_matrix_3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c43ce234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a 3x3 probability matrix around the midpoint of moving to the neighbouring zone or staying\n",
    "def get_probability_matrix(markov_matrix, current_zone):\n",
    "    prob_matrix = np.zeros(9 + void_zones)\n",
    "    midpoint = zone_to_coordinate(current_zone)\n",
    "    \n",
    "    k = 0\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            x = midpoint[1] + j-1\n",
    "            y = midpoint[0] + i-1\n",
    "            \n",
    "            if not (0 <= x < zone_columns):\n",
    "                prob_matrix[k] = 0\n",
    "                k += 1\n",
    "    \n",
    "            elif not (0 <= y < zone_rows):\n",
    "                prob_matrix[k] = 0\n",
    "                k += 1\n",
    "                \n",
    "            else:\n",
    "                coords = (y,x)\n",
    "                zone_nr = coordinate_to_zone(coords)\n",
    "                prob_matrix[k] = markov_matrix[zone_nr][current_zone]\n",
    "                k += 1\n",
    "    \n",
    "    #Determine the probability of disappearing if necessary\n",
    "    #Someone should be at the edge of the zones before they can disappear\n",
    "    if (x == zone_columns - 1 or x == 0) and (y == zone_rows - 1 or y == 0):\n",
    "        for i in range(void_zones):\n",
    "            prob_matrix[9+i] = markov_matrix[n_zones + i][current_zone]\n",
    "    else:\n",
    "        for i in range(void_zones):\n",
    "            prob_matrix[9+i] = 0\n",
    "            \n",
    "    return prob_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0350446",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert zone number to coordinate in zone grid\n",
    "def zone_to_coordinate(zone_nr):\n",
    "    x_pos = math.floor(zone_nr/zone_rows)\n",
    "    y_pos = zone_nr % zone_rows\n",
    "    return (y_pos,x_pos) #Return in the form of row nr., column nr., which corresponds to y,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e12f7e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert coordinate \n",
    "def coordinate_to_zone(coord):\n",
    "    x = coord[1] #equivalent to column nr.\n",
    "    y = coord[0] #equivalent to row nr.\n",
    "    return x*zone_rows + y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68834c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert density/probability array index to zone offset\n",
    "def array_index_to_zone_offset(index):\n",
    "    x_offset = index % 3 -1 #Column nr. offset\n",
    "    y_offset = math.floor(index/3) - 1 #Row nr. offset\n",
    "    return (y_offset, x_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0466163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to relate density to probability adjustment factor\n",
    "#Input is a array of densities\n",
    "def density_probability_function(density):\n",
    "    factor = 1 - ( 0.9 - 0.9 * np.power( math.e,-2*(density/max_density) ) )\n",
    "    return factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0a9728c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjust the probabilities of moving between zones according to density in neighbouring zones\n",
    "#The input probabilities is an 1D array for several zones\n",
    "def adjust_probability(probabilities, density):\n",
    "    probabilities = probabilities * density_probability_function( density )\n",
    "    probabilities[probabilities<0] = 0\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2920aaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a new zone for a person a markov matrix and a randomly generated number\n",
    "def get_new_zone(current_zone, markov_matrix):\n",
    "    \n",
    "    #Check if someone is in the disappearing zone\n",
    "    if (current_zone >= n_zones):\n",
    "        return current_zone\n",
    "    \n",
    "    #Get the probabilities for the zone and apply the randomness\n",
    "    probabilities_unadjusted = get_probability_matrix(markov_matrix,current_zone)\n",
    "    densities = get_density_matrix(density,current_zone) #Densities in the adjacent zones\n",
    "    probabilities = adjust_probability(probabilities_unadjusted, densities)\n",
    "\n",
    "    i = 0 #Iterator to keep track of which column/movement must be selected\n",
    "    if (sum(probabilities) == 0):\n",
    "        rand  = 0\n",
    "    else:\n",
    "        rand = random.random() * sum(probabilities)\n",
    "        \n",
    "    while rand > probabilities[i]:\n",
    "        rand -= probabilities[i]\n",
    "        i += 1\n",
    "    \n",
    "    if (i > 8):\n",
    "        return n_zones\n",
    "    \n",
    "    coord_offset = array_index_to_zone_offset(i)\n",
    "    current_coord = zone_to_coordinate(current_zone)\n",
    "    new_coord = (current_coord[0] + coord_offset[0], current_coord[1] + coord_offset[1])\n",
    "    new_zone = coordinate_to_zone(new_coord)\n",
    "    if (new_zone < 0):\n",
    "        new_zone = 0\n",
    "    return new_zone\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "010bf153",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the position of people according to the corresponding markov matrix\n",
    "def move():\n",
    "    global simulation_tuple\n",
    "    \n",
    "    #Loop through offboarders with markov matrix adjusted for density\n",
    "    markov_matrix = markov_matrix_offboarding\n",
    "    \n",
    "    for zone in blocked_zones:\n",
    "        markov_matrix = block_zone(markov_matrix, zone)\n",
    "    \n",
    "    for offboarder_ID, current_zone in offboarding_people_locs.items():\n",
    "        \n",
    "        new_zone = get_new_zone(current_zone, markov_matrix)\n",
    "        \n",
    "        offboarding_people_locs[offboarder_ID] = new_zone\n",
    "        simulation_tuple.extend([[offboarder_ID,True,False,time,new_zone]])\n",
    "        \n",
    "        density[zone_to_coordinate(current_zone)] -= 1/zone_area\n",
    "        density[zone_to_coordinate(new_zone)] += 1/zone_area\n",
    "    \n",
    "    #Loop through onboarders with markov matrix adjusted for density and whether there is a train\n",
    "    if train_present_top:\n",
    "        markov_matrix = markov_matrix_onboarding_train_top\n",
    "    elif train_present_bottom:\n",
    "        markov_matrix = markov_matrix_onboarding_train_bottom\n",
    "    else:\n",
    "        markov_matrix = markov_matrix_onboarding_no_train\n",
    "    \n",
    "    for zone in blocked_zones:\n",
    "        markov_matrix = block_zone(markov_matrix, zone)\n",
    "    \n",
    "    for onboarder_ID, current_zone in onboarding_people_locs.items():\n",
    "            \n",
    "        new_zone = get_new_zone(current_zone, markov_matrix)\n",
    "\n",
    "        onboarding_people_locs[onboarder_ID] = new_zone\n",
    "        simulation_tuple.extend([[onboarder_ID,False,True,time,new_zone]])\n",
    "        \n",
    "        density[zone_to_coordinate(current_zone)] -= 1/zone_area\n",
    "        density[zone_to_coordinate(new_zone)] += 1/zone_area\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61b98a8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-d7224522ff0c>\u001b[0m in \u001b[0;36mget_spawn_lib\u001b[1;34m(onboarding_offboarding)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0monboarding_offboarding\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'offboarding'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../people_input/incoming_people_offboarding_5_0.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m';'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mspawn_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1897\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1898\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1899\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1900\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Number of zones\n",
    "zone_rows = 14\n",
    "zone_columns = 67\n",
    "n_zones = zone_rows * zone_columns\n",
    "void_zones = 1 #Number of zones that people can disappear to\n",
    "\n",
    "#Variables that have to be determined in different steps\n",
    "markov_matrix_offboarding = pd.read_csv('../matrix_generator/results/offboarding/average.csv', header=None)\n",
    "markov_matrix_onboarding_no_train =  pd.read_csv('../matrix_generator/results/onboarding_no_train/average.csv', header=None)\n",
    "markov_matrix_onboarding_train_top =  pd.read_csv('../matrix_generator/results/onboarding_top/average.csv',header=None)\n",
    "markov_matrix_onboarding_train_bottom =  pd.read_csv('../matrix_generator/results/onboarding_bottom/average.csv',header=None)\n",
    "density_influence_table = None\n",
    "people_in_dictionary_off = get_spawn_lib('offboarding') #[50,51,52,53,54,55]}\n",
    "people_in_dictionary_on = get_spawn_lib('onboarding') #[1,2,3,4,5,6]}\n",
    "\n",
    "#Information about people\n",
    "current_ID = 1000 #People will also have an ID in the simulation, only a different one\n",
    "offboarding_people_locs = {} #Dictionary with person IDs as keys and zone IDs as values\n",
    "onboarding_people_locs = {} #Dictionary with person IDs as keys and zone IDs as values\n",
    "\n",
    "#Density information\n",
    "max_density = 5 #TODO\n",
    "zone_area = 2 #TODO\n",
    "#Set all densities to 0\n",
    "density_0 = np.zeros([zone_rows,zone_columns+1])\n",
    "density = density_0 #Dictionary with zone IDs as keys and density as values\n",
    "\n",
    "#Create dataframe to store the data over time\n",
    "simulation_tuple = ([[0,False,False,0,0]])\n",
    "\n",
    "#Nudges\n",
    "blocked_zones = [1,2,3]\n",
    "\n",
    "#Get train departure and arrival information\n",
    "train_data = get_train_data()\n",
    "\n",
    "train_present_top = False\n",
    "train_present_bottom = False\n",
    "\n",
    "#Initialize variables\n",
    "time =  list(people_in_dictionary_off.keys())[150] #Starting time of simulation\n",
    "sim_duration = 600 #How long the simulation lasts in seconds\n",
    "\n",
    "\n",
    "# SIMULATE \n",
    "\n",
    "#Start looping\n",
    "for i in range(sim_duration):\n",
    "    \n",
    "    check_train(time)\n",
    "    \n",
    "    move()\n",
    "    \n",
    "    spawn_people(time)\n",
    "    \n",
    "    time += 1\n",
    "\n",
    "simulation_df = pd.DataFrame(list(simulation_tuple), columns = ['ID','Offboarding','Onboarding','Time','Zone'])\n",
    "simulation_df = simulation_df.drop(0)\n",
    "simulation_df['x_pos'] = simulation_df['Zone'].divide(zone_rows).apply(np.floor)\n",
    "simulation_df['y_pos'] = (simulation_df['Zone']).mod(zone_rows)\n",
    "simulation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38bcf235",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'simulation_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-6f8e92809a3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msimulation_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test_results.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'simulation_df' is not defined"
     ]
    }
   ],
   "source": [
    "simulation_df.to_csv('test_results.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd37bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = simulation_df.groupby('ID').plot('x_pos','y_pos', xlim = [-1, 67], ylim = [-1,14]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd51192",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_probability_function(np.array([0,1,2,3,4,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e8cb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_matrix_onboarding_no_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

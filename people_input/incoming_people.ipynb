{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c572154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.lines as lines\n",
    "import datetime\n",
    "import math\n",
    "import csv\n",
    "import ast\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebe2769f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sociophysicsdatahandler in c:\\programdata\\anaconda3\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from sociophysicsdatahandler) (1.2.4)\n",
      "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from sociophysicsdatahandler) (8.2.0)\n",
      "Requirement already satisfied: pyarrow in c:\\programdata\\anaconda3\\lib\\site-packages (from sociophysicsdatahandler) (9.0.0)\n",
      "Requirement already satisfied: pyocclient in c:\\programdata\\anaconda3\\lib\\site-packages (from sociophysicsdatahandler) (0.6)\n",
      "Requirement already satisfied: scipy>=1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from sociophysicsdatahandler) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from sociophysicsdatahandler) (1.20.1)\n",
      "Requirement already satisfied: matplotlib>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sociophysicsdatahandler) (3.3.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0->sociophysicsdatahandler) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0->sociophysicsdatahandler) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0->sociophysicsdatahandler) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0->sociophysicsdatahandler) (1.3.1)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib>=2.0->sociophysicsdatahandler) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->sociophysicsdatahandler) (2021.1)\n",
      "Requirement already satisfied: requests>=2.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyocclient->sociophysicsdatahandler) (2.25.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.0.1->pyocclient->sociophysicsdatahandler) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.0.1->pyocclient->sociophysicsdatahandler) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.0.1->pyocclient->sociophysicsdatahandler) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.0.1->pyocclient->sociophysicsdatahandler) (4.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\utils\\_process_win32.py:145: ResourceWarning: unclosed file <_io.BufferedWriter name=4>\n",
      "  return process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\utils\\_process_win32.py:145: ResourceWarning: unclosed file <_io.BufferedReader name=5>\n",
      "  return process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\utils\\_process_win32.py:145: ResourceWarning: unclosed file <_io.BufferedReader name=6>\n",
      "  return process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "'cat' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\utils\\_process_win32.py:145: ResourceWarning: unclosed file <_io.BufferedWriter name=4>\n",
      "  return process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\utils\\_process_win32.py:145: ResourceWarning: unclosed file <_io.BufferedReader name=5>\n",
      "  return process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\utils\\_process_win32.py:145: ResourceWarning: unclosed file <_io.BufferedReader name=6>\n",
      "  return process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(action='once')\n",
    "\n",
    "!pip install sociophysicsdatahandler\n",
    "from sociophysicsDataHandler import SociophysicsDataHandler\n",
    "\n",
    "!cat auth.txt\n",
    "\n",
    "dh = SociophysicsDataHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45d5ed3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targeting path /storage/surfsara/ProRail_USE_LL_data/ehv/platform2.1/20220509/\n",
      "Files listed. Accessible as <this-object>.filelist\n",
      "                                                 path  \\\n",
      "0   /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "1   /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "2   /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "3   /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "4   /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "5   /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "6   /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "7   /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "8   /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "9   /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "10  /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "11  /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "12  /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "13  /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "14  /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "15  /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "16  /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "17  /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "18  /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "19  /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "20  /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "21  /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "22  /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "23  /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "\n",
      "                                              name  \\\n",
      "0   EHV_Platform2.1_2022050900_trajectorie.parquet   \n",
      "1   EHV_Platform2.1_2022050901_trajectorie.parquet   \n",
      "2   EHV_Platform2.1_2022050902_trajectorie.parquet   \n",
      "3   EHV_Platform2.1_2022050903_trajectorie.parquet   \n",
      "4   EHV_Platform2.1_2022050904_trajectorie.parquet   \n",
      "5   EHV_Platform2.1_2022050905_trajectorie.parquet   \n",
      "6   EHV_Platform2.1_2022050906_trajectorie.parquet   \n",
      "7   EHV_Platform2.1_2022050907_trajectorie.parquet   \n",
      "8   EHV_Platform2.1_2022050908_trajectorie.parquet   \n",
      "9   EHV_Platform2.1_2022050909_trajectorie.parquet   \n",
      "10  EHV_Platform2.1_2022050910_trajectorie.parquet   \n",
      "11  EHV_Platform2.1_2022050911_trajectorie.parquet   \n",
      "12  EHV_Platform2.1_2022050912_trajectorie.parquet   \n",
      "13  EHV_Platform2.1_2022050913_trajectorie.parquet   \n",
      "14  EHV_Platform2.1_2022050914_trajectorie.parquet   \n",
      "15  EHV_Platform2.1_2022050915_trajectorie.parquet   \n",
      "16  EHV_Platform2.1_2022050916_trajectorie.parquet   \n",
      "17  EHV_Platform2.1_2022050917_trajectorie.parquet   \n",
      "18  EHV_Platform2.1_2022050918_trajectorie.parquet   \n",
      "19  EHV_Platform2.1_2022050919_trajectorie.parquet   \n",
      "20  EHV_Platform2.1_2022050920_trajectorie.parquet   \n",
      "21  EHV_Platform2.1_2022050921_trajectorie.parquet   \n",
      "22  EHV_Platform2.1_2022050922_trajectorie.parquet   \n",
      "23  EHV_Platform2.1_2022050923_trajectorie.parquet   \n",
      "\n",
      "                                           attributes  \n",
      "0   {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "1   {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "2   {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "3   {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "4   {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "5   {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "6   {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "7   {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "8   {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "9   {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "10  {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "11  {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "12  {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "13  {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "14  {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "15  {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "16  {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "17  {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "18  {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "19  {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "20  {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "21  {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "22  {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "23  {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "                                                path  \\\n",
      "0  /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "1  /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "2  /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "3  /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "4  /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "5  /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "6  /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "7  /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "8  /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "9  /storage/surfsara/ProRail_USE_LL_data/ehv/plat...   \n",
      "\n",
      "                                             name  \\\n",
      "0  EHV_Platform2.1_2022050900_trajectorie.parquet   \n",
      "1  EHV_Platform2.1_2022050901_trajectorie.parquet   \n",
      "2  EHV_Platform2.1_2022050902_trajectorie.parquet   \n",
      "3  EHV_Platform2.1_2022050903_trajectorie.parquet   \n",
      "4  EHV_Platform2.1_2022050904_trajectorie.parquet   \n",
      "5  EHV_Platform2.1_2022050905_trajectorie.parquet   \n",
      "6  EHV_Platform2.1_2022050906_trajectorie.parquet   \n",
      "7  EHV_Platform2.1_2022050907_trajectorie.parquet   \n",
      "8  EHV_Platform2.1_2022050908_trajectorie.parquet   \n",
      "9  EHV_Platform2.1_2022050909_trajectorie.parquet   \n",
      "\n",
      "                                          attributes  \n",
      "0  {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "1  {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "2  {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "3  {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "4  {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "5  {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "6  {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "7  {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "8  {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "9  {'{DAV:}getlastmodified': 'Mon, 14 Nov 2022 11...  \n",
      "trying to fetch: /storage/surfsara/ProRail_USE_LL_data/ehv/platform2.1/20220509//EHV_Platform2.1_2022050900_trajectorie.parquet\n",
      "data fetched. Accessible as <this-object>.df\n",
      "trying to fetch: /storage/surfsara/ProRail_USE_LL_data/ehv/platform2.1/20220509//EHV_Platform2.1_2022050901_trajectorie.parquet\n",
      "data fetched. Accessible as <this-object>.df\n",
      "trying to fetch: /storage/surfsara/ProRail_USE_LL_data/ehv/platform2.1/20220509//EHV_Platform2.1_2022050902_trajectorie.parquet\n",
      "data fetched. Accessible as <this-object>.df\n",
      "trying to fetch: /storage/surfsara/ProRail_USE_LL_data/ehv/platform2.1/20220509//EHV_Platform2.1_2022050903_trajectorie.parquet\n",
      "data fetched. Accessible as <this-object>.df\n",
      "trying to fetch: /storage/surfsara/ProRail_USE_LL_data/ehv/platform2.1/20220509//EHV_Platform2.1_2022050904_trajectorie.parquet\n",
      "data fetched. Accessible as <this-object>.df\n",
      "trying to fetch: /storage/surfsara/ProRail_USE_LL_data/ehv/platform2.1/20220509//EHV_Platform2.1_2022050905_trajectorie.parquet\n",
      "data fetched. Accessible as <this-object>.df\n",
      "trying to fetch: /storage/surfsara/ProRail_USE_LL_data/ehv/platform2.1/20220509//EHV_Platform2.1_2022050906_trajectorie.parquet\n",
      "data fetched. Accessible as <this-object>.df\n",
      "trying to fetch: /storage/surfsara/ProRail_USE_LL_data/ehv/platform2.1/20220509//EHV_Platform2.1_2022050907_trajectorie.parquet\n",
      "data fetched. Accessible as <this-object>.df\n",
      "trying to fetch: /storage/surfsara/ProRail_USE_LL_data/ehv/platform2.1/20220509//EHV_Platform2.1_2022050908_trajectorie.parquet\n",
      "data fetched. Accessible as <this-object>.df\n",
      "trying to fetch: /storage/surfsara/ProRail_USE_LL_data/ehv/platform2.1/20220509//EHV_Platform2.1_2022050909_trajectorie.parquet\n",
      "data fetched. Accessible as <this-object>.df\n",
      "trying to fetch: /storage/surfsara/ProRail_USE_LL_data/ehv/platform2.1/20220509//EHV_Platform2.1_2022050910_trajectorie.parquet\n",
      "data fetched. Accessible as <this-object>.df\n",
      "trying to fetch: /storage/surfsara/ProRail_USE_LL_data/ehv/platform2.1/20220509//EHV_Platform2.1_2022050911_trajectorie.parquet\n",
      "data fetched. Accessible as <this-object>.df\n",
      "trying to fetch: /storage/surfsara/ProRail_USE_LL_data/ehv/platform2.1/20220509//EHV_Platform2.1_2022050912_trajectorie.parquet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data fetched. Accessible as <this-object>.df\n",
      "trying to fetch: /storage/surfsara/ProRail_USE_LL_data/ehv/platform2.1/20220509//EHV_Platform2.1_2022050913_trajectorie.parquet\n",
      "data fetched. Accessible as <this-object>.df\n",
      "trying to fetch: /storage/surfsara/ProRail_USE_LL_data/ehv/platform2.1/20220509//EHV_Platform2.1_2022050914_trajectorie.parquet\n",
      "data fetched. Accessible as <this-object>.df\n",
      "trying to fetch: /storage/surfsara/ProRail_USE_LL_data/ehv/platform2.1/20220509//EHV_Platform2.1_2022050915_trajectorie.parquet\n",
      "data fetched. Accessible as <this-object>.df\n",
      "trying to fetch: /storage/surfsara/ProRail_USE_LL_data/ehv/platform2.1/20220509//EHV_Platform2.1_2022050916_trajectorie.parquet\n",
      "data fetched. Accessible as <this-object>.df\n",
      "trying to fetch: /storage/surfsara/ProRail_USE_LL_data/ehv/platform2.1/20220509//EHV_Platform2.1_2022050917_trajectorie.parquet\n",
      "data fetched. Accessible as <this-object>.df\n",
      "trying to fetch: /storage/surfsara/ProRail_USE_LL_data/ehv/platform2.1/20220509//EHV_Platform2.1_2022050918_trajectorie.parquet\n",
      "data fetched. Accessible as <this-object>.df\n",
      "trying to fetch: /storage/surfsara/ProRail_USE_LL_data/ehv/platform2.1/20220509//EHV_Platform2.1_2022050919_trajectorie.parquet\n",
      "data fetched. Accessible as <this-object>.df\n",
      "trying to fetch: /storage/surfsara/ProRail_USE_LL_data/ehv/platform2.1/20220509//EHV_Platform2.1_2022050920_trajectorie.parquet\n",
      "data fetched. Accessible as <this-object>.df\n",
      "trying to fetch: /storage/surfsara/ProRail_USE_LL_data/ehv/platform2.1/20220509//EHV_Platform2.1_2022050921_trajectorie.parquet\n",
      "data fetched. Accessible as <this-object>.df\n",
      "trying to fetch: /storage/surfsara/ProRail_USE_LL_data/ehv/platform2.1/20220509//EHV_Platform2.1_2022050922_trajectorie.parquet\n",
      "data fetched. Accessible as <this-object>.df\n",
      "trying to fetch: /storage/surfsara/ProRail_USE_LL_data/ehv/platform2.1/20220509//EHV_Platform2.1_2022050923_trajectorie.parquet\n",
      "data fetched. Accessible as <this-object>.df\n",
      "trying to fetch: /storage/surfsara/ProRail_USE_LL_data/ehv/background_images/EHV.Perron2.1_multisensor.png\n",
      "background fetched. Accessible as <this-object>.bg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def fetchData(path):\n",
    "  #Fetch and combine all data from a directory\n",
    "  file_list = dh.list_files(path)\n",
    "  print(dh.filelist)\n",
    "  n = file_list.name.size\n",
    "  print(dh.filelist.head(10))\n",
    "  df_array = np.empty(n, dtype=object)\n",
    "\n",
    "  for i in range(n):\n",
    "    dh.fetch_prorail_data_from_path(path + \"/\" + file_list.name[i]);\n",
    "    #Convert the date time column to actual date time\n",
    "    dh.df['date_time_utc'] = pd.to_datetime(dh.df['date_time_utc'], unit = 'ms')\n",
    "    #Swap x and y\n",
    "    column_titles = {'date_time_utc':'date_time_utc', 'tracked_object':'tracked_object', 'x_pos':'y_pos', 'y_pos':'x_pos'}\n",
    "    dh.df.rename(columns = column_titles, inplace = True)\n",
    "\n",
    "    df_array[i] = dh.df\n",
    "\n",
    "  return pd.concat(df_array)\n",
    "\n",
    "\n",
    "file_path = 'ehv/platform2.1/20220509/'\n",
    "\n",
    "\n",
    "# fetch the data from the first file\n",
    "df = fetchData(file_path);\n",
    "\n",
    "\n",
    "\n",
    "dh.fetch_background_image_from_path('ehv/background_images/EHV.Perron2.1_multisensor.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49f84406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5436765 5436778 5436779 ... 5476473 5476475 5476478]\n",
      "                         date_time_utc   y_pos    x_pos  \\\n",
      "tracked_object                                            \n",
      "5436765        2022-05-08 22:00:00.400  3133.0  47762.0   \n",
      "5436778        2022-05-08 22:01:06.000   204.0  72908.0   \n",
      "5436779        2022-05-08 22:01:06.700  3482.0  15312.0   \n",
      "5436780        2022-05-08 22:01:10.500  -613.0  70481.0   \n",
      "5436781        2022-05-08 22:01:18.100 -8028.0  72807.0   \n",
      "...                                ...     ...      ...   \n",
      "5476471        2022-05-09 21:22:50.800  2892.0  56922.0   \n",
      "5476472        2022-05-09 21:23:22.900  2744.0  36012.0   \n",
      "5476473        2022-05-09 21:23:55.000  3582.0   7330.0   \n",
      "5476475        2022-05-09 21:24:59.000  3495.0   7521.0   \n",
      "5476478        2022-05-09 21:43:19.700  2207.0   4020.0   \n",
      "\n",
      "                                       datetime  \n",
      "tracked_object                                   \n",
      "5436765        2022-05-09 00:00:00.400000+02:00  \n",
      "5436778               2022-05-09 00:01:06+02:00  \n",
      "5436779        2022-05-09 00:01:06.700000+02:00  \n",
      "5436780        2022-05-09 00:01:10.500000+02:00  \n",
      "5436781        2022-05-09 00:01:18.100000+02:00  \n",
      "...                                         ...  \n",
      "5476471        2022-05-09 23:22:50.800000+02:00  \n",
      "5476472        2022-05-09 23:23:22.900000+02:00  \n",
      "5476473               2022-05-09 23:23:55+02:00  \n",
      "5476475               2022-05-09 23:24:59+02:00  \n",
      "5476478        2022-05-09 23:43:19.700000+02:00  \n",
      "\n",
      "[14760 rows x 4 columns]\n",
      "                         date_time_utc   y_pos   x_pos  \\\n",
      "tracked_object                                           \n",
      "5436766        2022-05-08 22:00:16.000 -5249.0   862.0   \n",
      "5436767        2022-05-08 22:00:20.000 -5299.0   586.0   \n",
      "5436768        2022-05-08 22:00:21.300 -1219.0  1558.0   \n",
      "5436769        2022-05-08 22:00:23.800   456.0  9718.0   \n",
      "5436770        2022-05-08 22:00:24.800 -3199.0  1923.0   \n",
      "...                                ...     ...     ...   \n",
      "5476476        2022-05-09 21:35:46.400 -5106.0   308.0   \n",
      "5476477        2022-05-09 21:43:06.500 -5077.0   481.0   \n",
      "5476478        2022-05-09 21:43:19.700  2207.0  4020.0   \n",
      "5476479        2022-05-09 21:49:44.900 -5182.0   259.0   \n",
      "5476480        2022-05-09 21:54:01.100 -4893.0    62.0   \n",
      "\n",
      "                                       datetime  \n",
      "tracked_object                                   \n",
      "5436766               2022-05-09 00:00:16+02:00  \n",
      "5436767               2022-05-09 00:00:20+02:00  \n",
      "5436768        2022-05-09 00:00:21.300000+02:00  \n",
      "5436769        2022-05-09 00:00:23.800000+02:00  \n",
      "5436770        2022-05-09 00:00:24.800000+02:00  \n",
      "...                                         ...  \n",
      "5476476        2022-05-09 23:35:46.400000+02:00  \n",
      "5476477        2022-05-09 23:43:06.500000+02:00  \n",
      "5476478        2022-05-09 23:43:19.700000+02:00  \n",
      "5476479        2022-05-09 23:49:44.900000+02:00  \n",
      "5476480        2022-05-09 23:54:01.100000+02:00  \n",
      "\n",
      "[15901 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def above_line(df, line, alpha, x_tag='x_pos',y_tag='y_pos'):\n",
    "    above_line_series = df[y_tag] > - math.atan(alpha/360*2*math.pi)*(df[x_tag]-line[0])+line[1]\n",
    "    return above_line_series\n",
    "\n",
    "def below_line(df, line, alpha, x_tag='x_pos',y_tag='y_pos'):\n",
    "    below_line_series = df[y_tag] < - math.atan(alpha/360*2*math.pi)*(df[x_tag]-line[0])+line[1]\n",
    "    return below_line_series\n",
    "\n",
    "def left_of_line(df, line, alpha, x_tag='x_pos',y_tag='y_pos'):\n",
    "    left_of_line_series = df[x_tag] < line[0]\n",
    "    return left_of_line_series\n",
    "\n",
    "df_grouped_by_id = df.groupby('tracked_object')\n",
    "df_object_start_location = df_grouped_by_id.first()\n",
    "df_object_end_location = df_grouped_by_id.last()\n",
    "\n",
    "alpha = 0.8 \n",
    "boarding_line_1 = [-2e4,2e3] #x, y, angle (degrees)\n",
    "dx = 5e4\n",
    "boarding_line_1.append(boarding_line_1[0]+dx) # [2]: x of point 2\n",
    "boarding_line_1.append(boarding_line_1[1]-dx*math.tan(alpha/360*2*math.pi)) # [3]: y of point 2\n",
    "\n",
    "boarding_line_2 = [-2e4,-0.65e4] #x, y, angle (degrees)\n",
    "dx = 5e4\n",
    "boarding_line_2.append(boarding_line_2[0]+dx) # [2]: x of point 2\n",
    "boarding_line_2.append(boarding_line_2[1]-dx*math.tan(alpha/360*2*math.pi)) # [3]: y of point 2\n",
    "\n",
    "boarding_line_3 = [70000,-15000,70000,10000]\n",
    "\n",
    "boarding_line_4 = [10000,-15000,10000,10000]\n",
    "\n",
    "#If start location is above line 1, offboarding. same for below line 2. Also to the right of the vertical line\n",
    "\n",
    "offboarding_1 = above_line(df_object_start_location,boarding_line_1,alpha)\n",
    "offboarding_2 = below_line(df_object_start_location,boarding_line_2,alpha)\n",
    "offboarding_3 = (df_object_start_location['x_pos']>boarding_line_3[0])\n",
    "offboarding = offboarding_1 | offboarding_2 | offboarding_3\n",
    "\n",
    "#If end location is above line 1, onboarding. same for below line 2.\n",
    "\n",
    "onboarding_1 = above_line(df_object_end_location,boarding_line_1,alpha)\n",
    "onboarding_2 = below_line(df_object_end_location,boarding_line_2,alpha)\n",
    "onboarding_3 = (df_object_end_location['x_pos']>boarding_line_3[0])\n",
    "entering = left_of_line(df_object_start_location,boarding_line_4,0)\n",
    "onboarding_or_entering = onboarding_1 | onboarding_2 | onboarding_3 | entering\n",
    "onboarding_or_entering.head()\n",
    "\n",
    "\n",
    "list_offboarding = offboarding.loc[offboarding==True].index.values\n",
    "print(list_offboarding)\n",
    "\n",
    "\n",
    "incoming_people_offboarding = df_object_start_location.loc[offboarding==True]\n",
    "print(incoming_people_offboarding)\n",
    "\n",
    "\n",
    "incoming_people_onboarding = df_object_start_location.loc[onboarding_or_entering==True]\n",
    "#print(incoming_people_onboarding)\n",
    "\n",
    "incoming_people_entering = df_object_start_location.loc[entering==True]\n",
    "print(incoming_people_entering)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0315e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "<ipython-input-5-30b88cd6bad0>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  incoming_people_entering['date_time_unix']=incoming_people_entering['date_time_utc'].map(lambda a: get_timestamp(a))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracked_object\n",
      "5436765    1652040000\n",
      "5436778    1652040066\n",
      "5436779    1652040066\n",
      "5436780    1652040070\n",
      "5436781    1652040078\n",
      "              ...    \n",
      "5476471    1652124170\n",
      "5476472    1652124202\n",
      "5476473    1652124235\n",
      "5476475    1652124299\n",
      "5476478    1652125399\n",
      "Name: date_time_unix, Length: 14760, dtype: int64\n",
      "1649018000\n",
      "1649019000\n",
      "1649020000\n",
      "1649021000\n",
      "1649022000\n",
      "1649023000\n",
      "1649024000\n",
      "1649025000\n",
      "1649026000\n",
      "1649027000\n",
      "1649028000\n",
      "1649029000\n",
      "1649030000\n",
      "1649031000\n",
      "1649032000\n",
      "1649033000\n",
      "1649034000\n",
      "1649035000\n",
      "1649036000\n",
      "1649037000\n",
      "1649038000\n",
      "1649039000\n",
      "1649040000\n",
      "1649041000\n",
      "1649042000\n",
      "1649043000\n",
      "1649044000\n",
      "1649045000\n",
      "1649046000\n",
      "1649047000\n",
      "1649048000\n",
      "1649049000\n",
      "1649050000\n",
      "1649051000\n",
      "1649052000\n",
      "1649053000\n",
      "1649054000\n",
      "1649055000\n",
      "1649056000\n",
      "1649057000\n",
      "1649058000\n",
      "1649059000\n",
      "1649060000\n",
      "1649061000\n",
      "1649062000\n",
      "1649063000\n",
      "1649064000\n",
      "1649065000\n",
      "1649066000\n",
      "1649067000\n",
      "1649068000\n",
      "1649069000\n",
      "1649070000\n",
      "1649071000\n",
      "1649072000\n",
      "1649073000\n",
      "1649074000\n",
      "1649075000\n",
      "1649076000\n",
      "1649077000\n",
      "1649078000\n",
      "1649079000\n",
      "1649080000\n",
      "1649081000\n",
      "1649082000\n",
      "1649083000\n",
      "1649084000\n",
      "1649085000\n",
      "1649086000\n",
      "1649087000\n",
      "1649088000\n",
      "1649089000\n",
      "1649090000\n",
      "1649091000\n",
      "1649092000\n",
      "1649093000\n",
      "1649094000\n",
      "1649095000\n",
      "1649096000\n",
      "1649097000\n",
      "1649098000\n",
      "1649099000\n",
      "1649100000\n",
      "1649101000\n",
      "1649102000\n",
      "1649103000\n",
      "{}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "def get_timestamp(utc_time):\n",
    "    return int(datetime.datetime.timestamp(utc_time))\n",
    "\n",
    "incoming_people_entering['date_time_unix']=incoming_people_entering['date_time_utc'].map(lambda a: get_timestamp(a))\n",
    "incoming_people_offboarding['date_time_unix']=incoming_people_offboarding['date_time_utc'].map(lambda a: get_timestamp(a))\n",
    "print(incoming_people_offboarding['date_time_unix'])\n",
    "\n",
    "dictionary_people_entering = {}\n",
    "dictionary_people_offboarding = {}\n",
    "\n",
    "def filter_on_timestamp(unix_timestamp,df):\n",
    "    temp_list = []\n",
    "    temp_df = df.loc[df['date_time_unix']==unix_timestamp]\n",
    "    for index, row in temp_df.iterrows():\n",
    "        temp_list.append([row['x_pos'],row['y_pos']])\n",
    "    return(temp_list)\n",
    "\n",
    "#for i in range(1649017471,1649102349):\n",
    "for i in range(1649017471,1649017471+24*3600):\n",
    "    if i%1000==0:\n",
    "        print(i)\n",
    "    \n",
    "    temp = filter_on_timestamp(i,incoming_people_entering)\n",
    "    if temp != []:\n",
    "        dictionary_people_entering[i] = temp\n",
    "        \n",
    "    temp = filter_on_timestamp(i,incoming_people_offboarding)\n",
    "    if temp != []:\n",
    "        dictionary_people_offboarding[i] = temp\n",
    "\n",
    "print(dictionary_people_entering)\n",
    "print(dictionary_people_offboarding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d49a68c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "x=4\n",
    "y=6\n",
    "if 3<x<5<y<7:\n",
    "    print('s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "281fe71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert coordinates to grid locations\n",
    "dict_people_entering_zones = dictionary_people_entering.copy()\n",
    "dict_people_offboarding_zones = dictionary_people_offboarding.copy()\n",
    "\n",
    "patch_width = 1000\n",
    "patch_height = 1000\n",
    "size = (patch_width, patch_height)\n",
    "\n",
    "total_patches = (67,14)\n",
    "\n",
    "o_x = 5000\n",
    "o_y = -10000\n",
    "origin = (o_x,o_y)\n",
    "\n",
    "for key in dictionary_people_entering.keys():\n",
    "    zones = []\n",
    "    \n",
    "    for pos in dictionary_people_entering[key]:\n",
    "        x_pos = pos[0]\n",
    "        x_pos = max(min(x_pos,71999), 5001) # 5000 72000\n",
    "        y_pos = pos[1] \n",
    "        y_pos = max(min(y_pos,3999), -9999)# -10000 4000\n",
    "        i = np.floor((x_pos-origin[0])/size[0])\n",
    "        j = np.floor((y_pos-origin[1])/size[1])\n",
    "\n",
    "        total_x_patches = total_patches[0]\n",
    "        total_y_patches = total_patches[1]\n",
    "\n",
    "        zones.append((i*total_y_patches)+j)\n",
    "        \n",
    "    dict_people_entering_zones[key] = zones\n",
    "\n",
    "    \n",
    "for key in dictionary_people_offboarding.keys():\n",
    "    zones = []\n",
    "    \n",
    "    for pos in dictionary_people_offboarding[key]:\n",
    "        x_pos = pos[0]\n",
    "        x_pos = max(min(x_pos,71999), 5001) # 5000 72000\n",
    "        y_pos = pos[1] \n",
    "        y_pos = max(min(x_pos,3999), -9999)# -10000 4000\n",
    "        i = np.floor((x_pos-origin[0])/size[0])\n",
    "        j = np.floor((y_pos-origin[1])/size[1])\n",
    "\n",
    "        total_x_patches = total_patches[0]\n",
    "        total_y_patches = total_patches[1]\n",
    "\n",
    "        zones.append((i*total_y_patches)+j)\n",
    "        \n",
    "    dict_people_offboarding_zones[key] = zones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccb1114f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_people_offboarding_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57df7475",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('incoming_people_entering_5_0.csv', 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile, delimiter=';',escapechar=' ', quoting=csv.QUOTE_NONE)\n",
    "    for key in dict_people_entering_zones.keys():\n",
    "       csvwriter.writerow([key,dict_people_entering_zones[key]])\n",
    "    \n",
    "with open('incoming_people_offboarding_5_0.csv', 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile, delimiter=';',escapechar=' ', quoting=csv.QUOTE_NONE)\n",
    "    for key in dict_people_offboarding_zones.keys():\n",
    "       csvwriter.writerow([key,dict_people_offboarding_zones[key]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55420302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_people_entering_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5c91a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

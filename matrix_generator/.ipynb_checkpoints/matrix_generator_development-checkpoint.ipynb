{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ea9c5f5",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c2ea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccb0e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libraries.dataManipulation import *\n",
    "from libraries.gridManipulation import *\n",
    "from data_preparator import *\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbaa0bd",
   "metadata": {},
   "source": [
    "# Create and plot grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb7c0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRID CONFIGURATION IS DECLARED\n",
    "o_x = 5000\n",
    "o_y = -10000\n",
    "o = (o_x,o_y)\n",
    "\n",
    "#TOTAL GRID SHOULD BE SIZE 67000x13000\n",
    "patch_width = 1000\n",
    "patch_height = 1000\n",
    "patch_size = (patch_width, patch_height)\n",
    "\n",
    "total_patches = (67,14)\n",
    "abs_total_patches = total_patches[0]*total_patches[1]\n",
    "\n",
    "grid_angle = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e610742",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRID IS CREATED USING CONFIG\n",
    "grid = create_grid(o, patch_size, total_patches, grid_angle)\n",
    "#GRID IS PLOTTED ON STATION\n",
    "plot_grid(grid, 'ehv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521e08ef",
   "metadata": {},
   "source": [
    "# Get data and separate by direction and train presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540671ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%capture\n",
    "data = getDay(20220314,'ehv')\n",
    "data = data.drop(data[data.x_pos < o_x].index)\n",
    "data = data.drop(data[data.y_pos < o_y].index)\n",
    "data = data.drop(data[data.x_pos > (total_patches[0]-1)*patch_width].index)\n",
    "data = data.drop(data[data.y_pos > (total_patches[1]-1)*patch_height].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95763d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7d1ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%capture\n",
    "(data_on_array ,data_off) = data_division(data)\n",
    "#data_on_array = [data_on_no_train, data_on_train_top, data_on_train_bottom, data_on_train_both]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4452a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_on_no_train = data_on_array[0]\n",
    "data_on_train_top = data_on_array[1]\n",
    "data_on_train_bottom = data_on_array[2]\n",
    "data_on_train_both = data_on_array[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fb52ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_off"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96287539",
   "metadata": {},
   "source": [
    "# Frequency calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977e120c",
   "metadata": {},
   "source": [
    "Now that the data has been prepared, and divided into 5 different dataframes, the data will be processed, and one matrix will be created out of each dataframe.\n",
    "For all of the observed day data so far, there are no moments where 2 trains are in the platform at the same time, so a matrix for this situation cannot be created. For that reason only the following matrices will be computed:\n",
    "- Transition matrix for offboarding\n",
    "- Transition matrix for onboarding without a train in the platform\n",
    "- Transition matrix for onboarding with a train at the top of the platform\n",
    "- Transition matrix for onboarding with a train at the bottom of the platform\n",
    "\n",
    "The algorythm for the computation of the matrix should be the same for all 4 dataframe, so I will be using the offboarding data for development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f80cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zone(x_pos, y_pos):\n",
    "    origin = o\n",
    "    size = patch_size\n",
    "    \n",
    "    i = np.floor((x_pos-origin[0])/size[0])\n",
    "    j = np.floor((y_pos-origin[1])/size[1])\n",
    "    \n",
    "    total_x_patches = total_patches[0]\n",
    "    total_y_patches = total_patches[1]\n",
    "    \n",
    "    zone = (i*total_y_patches)+j\n",
    "    return int(zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86510aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print('Processing data_off...')\n",
    "data_off['zone'] = np.vectorize(zone)(data_off['x_pos'], data_off['y_pos'])\n",
    "print('...data_off processed.')\n",
    "\n",
    "print('Processing data_on_no_train...')\n",
    "data_on_no_train['zone'] = np.vectorize(zone)(data_on_no_train['x_pos'], data_on_no_train['y_pos'])\n",
    "print('...data_on_no_train processed.')\n",
    "\n",
    "print('Processing data_on_train_top...')\n",
    "data_on_train_top['zone'] = np.vectorize(zone)(data_on_train_top['x_pos'], data_on_train_top['y_pos'])\n",
    "print('...data_on_train_top processed.')\n",
    "\n",
    "print('Processing data_on_train_bottom...')\n",
    "data_on_train_bottom['zone'] = np.vectorize(zone)(data_on_train_bottom['x_pos'], data_on_train_bottom['y_pos'])\n",
    "print('...data_on_train_bottom processed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e3d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "people_list = data_off.tracked_object.unique()\n",
    "\n",
    "#Compute zone count\n",
    "zone_count = data_off['zone'].value_counts().to_dict()\n",
    "\n",
    "def compute_transition_counts(person, df):\n",
    "    # Create a copy of the dataframe before modifying it\n",
    "    person_moves = df[df['tracked_object']==person].copy()\n",
    "    # Use .loc to select the 'zone' column and assign the shifted values\n",
    "    person_moves.loc[:, 'next_zone'] = person_moves['zone'].shift(periods=-1)\n",
    "    person_moves = person_moves.fillna(-1)\n",
    "    person_moves['next_zone'] = person_moves['next_zone'].astype(int)\n",
    "    person_moves['transition'] = list(zip(person_moves['zone'], person_moves['next_zone']))\n",
    "    transition_count_series = person_moves.groupby('transition').size()\n",
    "    transition_counts_dict = transition_counts.to_dict()\n",
    "    return transition_counts_dict\n",
    "\n",
    "transition_counts_total = {}\n",
    "people_done = 0\n",
    "for person in people_list:\n",
    "    print(people_done*100/len(people_list))\n",
    "    transition_counts_total = Counter(transition_counts_total) + Counter(compute_transition_counts(person, data_off))\n",
    "    people_done+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
